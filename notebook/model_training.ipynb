{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Insurance.entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_99208\\1503841097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mInsurance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_factory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelFactory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mget_sample_model_config_yaml_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Insurance.entity'"
     ]
    }
   ],
   "source": [
    "from Insurance.entity.model_factory import ModelFactory,get_sample_model_config_yaml_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Insurance.component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model._base.LinearRegression"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import log\n",
    "import importlib\n",
    "from pyexpat import model\n",
    "import numpy as np\n",
    "import yaml\n",
    "from Insurance.exception import ProjectException\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from collections import namedtuple\n",
    "from typing import List\n",
    "from Insurance.logger import logging\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "GRID_SEARCH_KEY = 'grid_search'\n",
    "MODULE_KEY = 'module'\n",
    "CLASS_KEY = 'class'\n",
    "PARAM_KEY = 'params'\n",
    "MODEL_SELECTION_KEY = 'model_selection'\n",
    "SEARCH_PARAM_GRID_KEY = \"search_param_grid\"\n",
    "\n",
    "InitializedModelDetail = namedtuple(\"InitializedModelDetail\",\n",
    "                                    [\"model_serial_number\", \"model\", \"param_grid_search\", \"model_name\"])\n",
    "\n",
    "GridSearchedBestModel = namedtuple(\"GridSearchedBestModel\", [\"model_serial_number\",\n",
    "                                                             \"model\",\n",
    "                                                             \"best_model\",\n",
    "                                                             \"best_parameters\",\n",
    "                                                             \"best_score\",\n",
    "                                                             ])\n",
    "\n",
    "BestModel = namedtuple(\"BestModel\", [\"model_serial_number\",\n",
    "                                     \"model\",\n",
    "                                     \"best_model\",\n",
    "                                     \"best_parameters\",\n",
    "                                     \"best_score\", ])\n",
    "\n",
    "MetricInfoArtifact = namedtuple(\"MetricInfoArtifact\",\n",
    "                                [\"model_name\", \"model_object\", \"train_rmse\", \"test_rmse\", \"train_accuracy\",\n",
    "                                 \"test_accuracy\", \"model_accuracy\", \"index_number\"])\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_classification_model(model_list: list, X_train:np.ndarray, y_train:np.ndarray, X_test:np.ndarray, y_test:np.ndarray, base_accuracy:float=0.6)->MetricInfoArtifact:\n",
    "    pass\n",
    "\n",
    "\n",
    "def evaluate_regression_model(model_list: list, X_train:np.ndarray, y_train:np.ndarray, X_test:np.ndarray, y_test:np.ndarray, base_accuracy:float=0.6) -> MetricInfoArtifact:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    This function compare multiple regression model return best model\n",
    "\n",
    "    Params:\n",
    "    model_list: List of model\n",
    "    X_train: Training dataset input feature\n",
    "    y_train: Training dataset target feature\n",
    "    X_test: Testing dataset input feature\n",
    "    y_test: Testing dataset input feature\n",
    "\n",
    "    return\n",
    "    It retured a named tuple\n",
    "    \n",
    "    MetricInfoArtifact = namedtuple(\"MetricInfo\",\n",
    "                                [\"model_name\", \"model_object\", \"train_rmse\", \"test_rmse\", \"train_accuracy\",\n",
    "                                 \"test_accuracy\", \"model_accuracy\", \"index_number\"])\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \n",
    "    \n",
    "        index_number = 0\n",
    "        metric_info_artifact = None\n",
    "        for model in model_list:\n",
    "            model_name = str(model)  #getting model name based on model object\n",
    "            logging.info(f\"{'>>'*30}Started evaluating model: [{type(model).__name__}] {'<<'*30}\")\n",
    "            \n",
    "            #Getting prediction for training and testing dataset\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            #Calculating r squared score on training and testing dataset\n",
    "            train_acc = r2_score(y_train, y_train_pred)\n",
    "            test_acc = r2_score(y_test, y_test_pred)\n",
    "            \n",
    "            #Calculating mean squared error on training and testing dataset\n",
    "            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "            # Calculating harmonic mean of train_accuracy and test_accuracy\n",
    "            model_accuracy = (2 * (train_acc * test_acc)) / (train_acc + test_acc)\n",
    "            diff_test_train_acc = abs(test_acc - train_acc)\n",
    "            \n",
    "            #logging all important metric\n",
    "            logging.info(f\"{'>>'*30} Score {'<<'*30}\")\n",
    "            logging.info(f\"Train Score\\t\\t Test Score\\t\\t Average Score\")\n",
    "            logging.info(f\"{train_acc}\\t\\t {test_acc}\\t\\t{model_accuracy}\")\n",
    "\n",
    "            logging.info(f\"{'>>'*30} Loss {'<<'*30}\")\n",
    "            logging.info(f\"Diff test train accuracy: [{diff_test_train_acc}].\") \n",
    "            logging.info(f\"Train root mean squared error: [{train_rmse}].\")\n",
    "            logging.info(f\"Test root mean squared error: [{test_rmse}].\")\n",
    "\n",
    "\n",
    "            #if model accuracy is greater than base accuracy and train and test score is within certain thershold\n",
    "            #we will accept that model as accepted model\n",
    "            if model_accuracy >= base_accuracy and diff_test_train_acc < 0.05:\n",
    "                base_accuracy = model_accuracy\n",
    "                metric_info_artifact = MetricInfoArtifact(model_name=model_name,\n",
    "                                                        model_object=model,\n",
    "                                                        train_rmse=train_rmse,\n",
    "                                                        test_rmse=test_rmse,\n",
    "                                                        train_accuracy=train_acc,\n",
    "                                                        test_accuracy=test_acc,\n",
    "                                                        model_accuracy=model_accuracy,\n",
    "                                                        index_number=index_number)\n",
    "\n",
    "                logging.info(f\"Acceptable model found {metric_info_artifact}. \")\n",
    "            index_number += 1\n",
    "        if metric_info_artifact is None:\n",
    "            logging.info(f\"No model found with higher accuracy than base accuracy\")\n",
    "        return metric_info_artifact\n",
    "    except Exception as e:\n",
    "        raise ProjectException(e, sys) from e\n",
    "\n",
    "\n",
    "def get_sample_model_config_yaml_file(export_dir: str):\n",
    "    try:\n",
    "        model_config = {\n",
    "            GRID_SEARCH_KEY: {\n",
    "                MODULE_KEY: \"sklearn.model_selection\",\n",
    "                CLASS_KEY: \"GridSearchCV\",\n",
    "                PARAM_KEY: {\n",
    "                    \"cv\": 3,\n",
    "                    \"verbose\": 1\n",
    "                }\n",
    "\n",
    "            },\n",
    "            MODEL_SELECTION_KEY: {\n",
    "                \"module_0\": {\n",
    "                    MODULE_KEY: \"module_of_model\",\n",
    "                    CLASS_KEY: \"ModelClassName\",\n",
    "                    PARAM_KEY:\n",
    "                        {\"param_name1\": \"value1\",\n",
    "                         \"param_name2\": \"value2\",\n",
    "                         },\n",
    "                    SEARCH_PARAM_GRID_KEY: {\n",
    "                        \"param_name\": ['param_value_1', 'param_value_2']\n",
    "                    }\n",
    "\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "        os.makedirs(export_dir, exist_ok=True)\n",
    "        export_file_path = os.path.join(export_dir, \"model.yaml\")\n",
    "        with open(export_file_path, 'w') as file:\n",
    "            yaml.dump(model_config, file)\n",
    "        return export_file_path\n",
    "    except Exception as e:\n",
    "        raise ProjectException(e, sys)\n",
    "\n",
    "\n",
    "class ModelFactory:\n",
    "    def __init__(self, model_config_path: str = None,):\n",
    "        try:\n",
    "            self.config: dict = ModelFactory.read_params(model_config_path)\n",
    "\n",
    "            self.grid_search_cv_module: str = self.config[GRID_SEARCH_KEY][MODULE_KEY]\n",
    "            self.grid_search_class_name: str = self.config[GRID_SEARCH_KEY][CLASS_KEY]\n",
    "            self.grid_search_property_data: dict = dict(self.config[GRID_SEARCH_KEY][PARAM_KEY])\n",
    "\n",
    "            self.models_initialization_config: dict = dict(self.config[MODEL_SELECTION_KEY])\n",
    "\n",
    "            self.initialized_model_list = None\n",
    "            self.grid_searched_best_model_list = None\n",
    "\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    @staticmethod\n",
    "    def update_property_of_class(instance_ref:object, property_data: dict):\n",
    "        try:\n",
    "            if not isinstance(property_data, dict):\n",
    "                raise Exception(\"property_data parameter required to dictionary\")\n",
    "            print(property_data)\n",
    "            for key, value in property_data.items():\n",
    "                logging.info(f\"Executing:$ {str(instance_ref)}.{key}={value}\")\n",
    "                setattr(instance_ref, key, value)\n",
    "            return instance_ref\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    @staticmethod\n",
    "    def read_params(config_path: str) -> dict:\n",
    "        try:\n",
    "            with open(config_path) as yaml_file:\n",
    "                config:dict = yaml.safe_load(yaml_file)\n",
    "            return config\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    @staticmethod\n",
    "    def class_for_name(module_name:str, class_name:str):\n",
    "        try:\n",
    "            # load the module, will raise ImportError if module cannot be loaded\n",
    "            module = importlib.import_module(module_name)\n",
    "            # get the class, will raise AttributeError if class cannot be found\n",
    "            logging.info(f\"Executing command: from {module} import {class_name}\")\n",
    "            class_ref = getattr(module, class_name)\n",
    "            return class_ref\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    def execute_grid_search_operation(self, initialized_model: InitializedModelDetail, input_feature,\n",
    "                                      output_feature) -> GridSearchedBestModel:\n",
    "        \"\"\"\n",
    "        excute_grid_search_operation(): function will perform paramter search operation and\n",
    "        it will return you the best optimistic  model with best paramter:\n",
    "        estimator: Model object\n",
    "        param_grid: dictionary of paramter to perform search operation\n",
    "        input_feature: your all input features\n",
    "        output_feature: Target/Dependent features\n",
    "        ================================================================================\n",
    "        return: Function will return GridSearchOperation object\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # instantiating GridSearchCV class\n",
    "            \n",
    "           \n",
    "            grid_search_cv_ref = ModelFactory.class_for_name(module_name=self.grid_search_cv_module,\n",
    "                                                             class_name=self.grid_search_class_name\n",
    "                                                             )\n",
    "\n",
    "            grid_search_cv = grid_search_cv_ref(estimator=initialized_model.model,\n",
    "                                                param_grid=initialized_model.param_grid_search)\n",
    "            grid_search_cv = ModelFactory.update_property_of_class(grid_search_cv,\n",
    "                                                                   self.grid_search_property_data)\n",
    "\n",
    "            \n",
    "            message = f'{\">>\"* 30} f\"Training {type(initialized_model.model).__name__} Started.\" {\"<<\"*30}'\n",
    "            logging.info(message)\n",
    "            grid_search_cv.fit(input_feature, output_feature)\n",
    "            message = f'{\">>\"* 30} f\"Training {type(initialized_model.model).__name__}\" completed {\"<<\"*30}'\n",
    "            grid_searched_best_model = GridSearchedBestModel(model_serial_number=initialized_model.model_serial_number,\n",
    "                                                             model=initialized_model.model,\n",
    "                                                             best_model=grid_search_cv.best_estimator_,\n",
    "                                                             best_parameters=grid_search_cv.best_params_,\n",
    "                                                             best_score=grid_search_cv.best_score_\n",
    "                                                             )\n",
    "            \n",
    "            return grid_searched_best_model\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    def get_initialized_model_list(self) -> List[InitializedModelDetail]:\n",
    "        \"\"\"\n",
    "        This function will return a list of model details.\n",
    "        return List[ModelDetail]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            initialized_model_list = []\n",
    "            for model_serial_number in self.models_initialization_config.keys():\n",
    "\n",
    "                model_initialization_config = self.models_initialization_config[model_serial_number]\n",
    "                model_obj_ref = ModelFactory.class_for_name(module_name=model_initialization_config[MODULE_KEY],\n",
    "                                                            class_name=model_initialization_config[CLASS_KEY]\n",
    "                                                            )\n",
    "                model = model_obj_ref()\n",
    "                \n",
    "                if PARAM_KEY in model_initialization_config:\n",
    "                    model_obj_property_data = dict(model_initialization_config[PARAM_KEY])\n",
    "                    model = ModelFactory.update_property_of_class(instance_ref=model,\n",
    "                                                                  property_data=model_obj_property_data)\n",
    "\n",
    "                param_grid_search = model_initialization_config[SEARCH_PARAM_GRID_KEY]\n",
    "                model_name = f\"{model_initialization_config[MODULE_KEY]}.{model_initialization_config[CLASS_KEY]}\"\n",
    "\n",
    "                model_initialization_config = InitializedModelDetail(model_serial_number=model_serial_number,\n",
    "                                                                     model=model,\n",
    "                                                                     param_grid_search=param_grid_search,\n",
    "                                                                     model_name=model_name\n",
    "                                                                     )\n",
    "\n",
    "                initialized_model_list.append(model_initialization_config)\n",
    "\n",
    "            self.initialized_model_list = initialized_model_list\n",
    "            return self.initialized_model_list\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    def initiate_best_parameter_search_for_initialized_model(self, initialized_model: InitializedModelDetail,\n",
    "                                                             input_feature,\n",
    "                                                             output_feature) -> GridSearchedBestModel:\n",
    "        \"\"\"\n",
    "        initiate_best_model_parameter_search(): function will perform paramter search operation and\n",
    "        it will return you the best optimistic  model with best paramter:\n",
    "        estimator: Model object\n",
    "        param_grid: dictionary of paramter to perform search operation\n",
    "        input_feature: your all input features\n",
    "        output_feature: Target/Dependent features\n",
    "        ================================================================================\n",
    "        return: Function will return a GridSearchOperation\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.execute_grid_search_operation(initialized_model=initialized_model,\n",
    "                                                      input_feature=input_feature,\n",
    "                                                      output_feature=output_feature)\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    def initiate_best_parameter_search_for_initialized_models(self,\n",
    "                                                              initialized_model_list: List[InitializedModelDetail],\n",
    "                                                              input_feature,\n",
    "                                                              output_feature) -> List[GridSearchedBestModel]:\n",
    "\n",
    "        try:\n",
    "            self.grid_searched_best_model_list = []\n",
    "            for initialized_model_list in initialized_model_list:\n",
    "                grid_searched_best_model = self.initiate_best_parameter_search_for_initialized_model(\n",
    "                    initialized_model=initialized_model_list,\n",
    "                    input_feature=input_feature,\n",
    "                    output_feature=output_feature\n",
    "                )\n",
    "                self.grid_searched_best_model_list.append(grid_searched_best_model)\n",
    "            return self.grid_searched_best_model_list\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    @staticmethod\n",
    "    def get_model_detail(model_details: List[InitializedModelDetail],\n",
    "                         model_serial_number: str) -> InitializedModelDetail:\n",
    "        \"\"\"\n",
    "        This function return ModelDetail\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for model_data in model_details:\n",
    "                if model_data.model_serial_number == model_serial_number:\n",
    "                    return model_data\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    @staticmethod\n",
    "    def get_best_model_from_grid_searched_best_model_list(grid_searched_best_model_list: List[GridSearchedBestModel],\n",
    "                                                          base_accuracy=0.6\n",
    "                                                          ) -> BestModel:\n",
    "        try:\n",
    "            best_model = None\n",
    "            for grid_searched_best_model in grid_searched_best_model_list:\n",
    "                if base_accuracy < grid_searched_best_model.best_score:\n",
    "                    logging.info(f\"Acceptable model found:{grid_searched_best_model}\")\n",
    "                    base_accuracy = grid_searched_best_model.best_score\n",
    "\n",
    "                    best_model = grid_searched_best_model\n",
    "            if not best_model:\n",
    "                raise Exception(f\"None of Model has base accuracy: {base_accuracy}\")\n",
    "            logging.info(f\"Best model: {best_model}\")\n",
    "            return best_model\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys) from e\n",
    "\n",
    "    def get_best_model(self, X, y,base_accuracy=0.6) -> BestModel:\n",
    "        try:\n",
    "            logging.info(\"Started Initializing model from config file\")\n",
    "            initialized_model_list = self.get_initialized_model_list()\n",
    "            logging.info(f\"Initialized model: {initialized_model_list}\")\n",
    "            grid_searched_best_model_list = self.initiate_best_parameter_search_for_initialized_models(\n",
    "                initialized_model_list=initialized_model_list,\n",
    "                input_feature=X,\n",
    "                output_feature=y\n",
    "            )\n",
    "            return ModelFactory.get_best_model_from_grid_searched_best_model_list(grid_searched_best_model_list,\n",
    "                                                                                  base_accuracy=base_accuracy)\n",
    "        except Exception as e:\n",
    "            raise ProjectException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from Insurance.exception import ProjectException\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import dill\n",
    "import pandas as pd\n",
    "from Insurance.constant import *\n",
    "\n",
    "def write_yaml_file(file_path:str,data:dict=None):\n",
    "    \"\"\"\n",
    "    Create yaml file \n",
    "    file_path: str\n",
    "    data: dict\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        with open(file_path,\"w\") as yaml_file:\n",
    "            if data is not None:\n",
    "                yaml.dump(data,yaml_file)\n",
    "    except Exception as e:\n",
    "        raise ProjectException(e,sys)\n",
    "\n",
    "def read_yaml_file(file_path:str)->dict:\n",
    "    \"\"\"\n",
    "    Reads a YAML file and returns the contents as a dictionary.\n",
    "    file_path: str\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as yaml_file:\n",
    "            return yaml.safe_load(yaml_file)\n",
    "    except Exception as e:\n",
    "        raise ProjectException(e,sys) from e\n",
    "\n",
    "def save_numpy_array_data(file_path: str, array: np.array):\n",
    "    \"\"\"\n",
    "    Save numpy array data to file\n",
    "    file_path: str location of file to save\n",
    "    array: np.array data to save\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        with open(file_path, 'wb') as file_obj:\n",
    "            np.save(file_obj, array)\n",
    "    except Exception as e:\n",
    "        raise ProjectException(e, sys) from e\n",
    "\n",
    "def load_numpy_array_data(file_path: str) -> np.array:\n",
    "    \"\"\"\n",
    "    load numpy array data from file\n",
    "    file_path: str location of file to load\n",
    "    return: np.array data loaded\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file_obj:\n",
    "            return np.load(file_obj)\n",
    "    except Exception as e:\n",
    "        raise ProjectException(e, sys) from e\n",
    "\n",
    "def save_object(file_path:str,obj):\n",
    "    \"\"\"\n",
    "    file_path: str\n",
    "    obj: Any sort of object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dir_path = os.path.dirname(file_path)\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "        with open(file_path, \"wb\") as file_obj:\n",
    "            dill.dump(obj, file_obj)\n",
    "    except Exception as e:\n",
    "        raise ProjectException(e,sys) from e\n",
    "\n",
    "def load_object(file_path:str):\n",
    "    \"\"\"\n",
    "    file_path: str\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file_obj:\n",
    "            return dill.load(file_obj)\n",
    "    except Exception as e:\n",
    "        raise ProjectException(e,sys) from e\n",
    "\n",
    "def load_data(file_path: str, schema_file_path: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        datatset_schema = read_yaml_file(schema_file_path)\n",
    "\n",
    "        schema = datatset_schema[DATASET_SCHEMA_COLUMNS_KEY]\n",
    "\n",
    "        dataframe = pd.read_csv(file_path)\n",
    "\n",
    "        error_messgae = \"\"\n",
    "\n",
    "\n",
    "        for column in dataframe.columns:\n",
    "            if column in list(schema.keys()):\n",
    "                dataframe[column].astype(schema[column])\n",
    "            else:\n",
    "                error_messgae = f\"{error_messgae} \\nColumn: [{column}] is not in the schema.\"\n",
    "        if len(error_messgae) > 0:\n",
    "            raise Exception(error_messgae)\n",
    "        return dataframe\n",
    "\n",
    "    except Exception as e:\n",
    "        raise ProjectException(e,sys) from e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Insurance import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_config = r'C:\\Users\\athir\\OneDrive\\Documents\\Internship\\Insurance-Premium-Prediction\\config\\model.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_factory = ModelFactory(model_config_path = model_file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': True}\n",
      "{'min_samples_leaf': 3}\n",
      "{'criterion': 'squared_error', 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "model_list = model_factory.get_initialized_model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InitializedModelDetail(model_serial_number='module_0', model=LinearRegression(), param_grid_search={'fit_intercept': [True, False]}, model_name='sklearn.linear_model.LinearRegression')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = r\"C:\\Users\\athir\\OneDrive\\Documents\\Internship\\Insurance-Premium-Prediction\\Insurance\\artifact\\data_transformation\\2022-08-03-19-59-23\\transformed_data\\train\\insurance.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_numpy_array_data(data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data[:,:-1],data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': True}\n",
      "{'min_samples_leaf': 3}\n",
      "{'criterion': 'squared_error', 'min_samples_leaf': 2}\n",
      "{'cv': 5, 'verbose': 2}\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] END .................................fit_intercept=True; total time=   0.1s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END .................................fit_intercept=True; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "[CV] END ................................fit_intercept=False; total time=   0.0s\n",
      "{'cv': 5, 'verbose': 2}\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END .................................min_samples_leaf=5; total time=   0.4s\n",
      "[CV] END .................................min_samples_leaf=5; total time=   0.1s\n",
      "[CV] END .................................min_samples_leaf=5; total time=   0.2s\n",
      "[CV] END .................................min_samples_leaf=5; total time=   0.1s\n",
      "[CV] END .................................min_samples_leaf=5; total time=   0.2s\n",
      "[CV] END .................................min_samples_leaf=7; total time=   0.2s\n",
      "[CV] END .................................min_samples_leaf=7; total time=   0.1s\n",
      "[CV] END .................................min_samples_leaf=7; total time=   0.3s\n",
      "[CV] END .................................min_samples_leaf=7; total time=   0.3s\n",
      "[CV] END .................................min_samples_leaf=7; total time=   0.3s\n",
      "[CV] END ................................min_samples_leaf=12; total time=   0.4s\n",
      "[CV] END ................................min_samples_leaf=12; total time=   0.2s\n",
      "[CV] END ................................min_samples_leaf=12; total time=   0.1s\n",
      "[CV] END ................................min_samples_leaf=12; total time=   0.1s\n",
      "[CV] END ................................min_samples_leaf=12; total time=   0.1s\n",
      "{'cv': 5, 'verbose': 2}\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=5; total time=   0.0s\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=5; total time=   0.0s\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=5; total time=   0.0s\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=5; total time=   0.0s\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=5; total time=   0.0s\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=7; total time=   0.0s\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=7; total time=   0.0s\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=7; total time=   0.0s\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=7; total time=   0.0s\n",
      "[CV] END .........criterion=friedman_mse, min_samples_leaf=7; total time=   0.0s\n",
      "[CV] END ........criterion=friedman_mse, min_samples_leaf=12; total time=   0.0s\n",
      "[CV] END ........criterion=friedman_mse, min_samples_leaf=12; total time=   0.0s\n",
      "[CV] END ........criterion=friedman_mse, min_samples_leaf=12; total time=   0.0s\n",
      "[CV] END ........criterion=friedman_mse, min_samples_leaf=12; total time=   0.0s\n",
      "[CV] END ........criterion=friedman_mse, min_samples_leaf=12; total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "best_model= model_factory.get_best_model(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 12}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchedBestModel(model_serial_number='module_1', model=RandomForestRegressor(min_samples_leaf=3), best_model=RandomForestRegressor(min_samples_leaf=12), best_parameters={'min_samples_leaf': 12}, best_score=0.8475513622389419)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_leaf=12)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GridSearchedBestModel(model_serial_number='module_0', model=LinearRegression(), best_model=LinearRegression(), best_parameters={'fit_intercept': True}, best_score=0.7400629679529622),\n",
       " GridSearchedBestModel(model_serial_number='module_1', model=RandomForestRegressor(min_samples_leaf=3), best_model=RandomForestRegressor(min_samples_leaf=12), best_parameters={'min_samples_leaf': 12}, best_score=0.8475513622389419),\n",
       " GridSearchedBestModel(model_serial_number='module_2', model=GradientBoostingRegressor(criterion='squared_error', min_samples_leaf=2), best_model=GradientBoostingRegressor(min_samples_leaf=12), best_parameters={'criterion': 'friedman_mse', 'min_samples_leaf': 12}, best_score=0.8459261746904752)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_factory.grid_searched_best_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f0586cd27c56ed29f660f25c9a105906c9e6cf9a596f555253bf98819735a58"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
